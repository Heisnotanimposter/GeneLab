{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1848242,
          "sourceType": "datasetVersion",
          "datasetId": 1099198
        }
      ],
      "dockerImageVersionId": 30646,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heisnotanimposter/GeneLab/blob/main/GeneMLnotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Step 1: Install Necessary Packages\n",
        "# -------------------------------\n",
        "\n",
        "# Install required libraries\n",
        "!pip install -q biopython stable-baselines3 gymnasium shimmy\n",
        "\n",
        "# -------------------------------\n",
        "# Step 2: Import Libraries\n",
        "# -------------------------------\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from Bio import Entrez, SeqIO\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from google.colab import drive\n",
        "import datetime  # Added import for datetime\n",
        "\n",
        "# -------------------------------\n",
        "# Step 3: Mount Google Drive\n",
        "# -------------------------------\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to your dataset\n",
        "data_dir = '/content/drive/MyDrive/GeneLab/DNAsequential/'  # Update this path based on your Drive structure\n",
        "\n",
        "# Verify that the files exist by listing the directory\n",
        "print(\"Listing files in the dataset directory:\")\n",
        "!ls {data_dir}\n",
        "\n",
        "# Define individual file paths\n",
        "human_file = os.path.join(data_dir, 'human.txt')\n",
        "dog_file = os.path.join(data_dir, 'dog.txt')\n",
        "chimpanzee_file = os.path.join(data_dir, 'chimpanzee.txt')\n",
        "example_dna_file = os.path.join(data_dir, 'example_dna.fa')\n",
        "\n",
        "# Verify file existence\n",
        "for file in [human_file, dog_file, chimpanzee_file, example_dna_file]:\n",
        "    if not os.path.exists(file):\n",
        "        print(f'File {file} not found. Please check the path.')\n",
        "    else:\n",
        "        print(f'File {file} found.')\n",
        "\n",
        "# -------------------------------\n",
        "# Step 4: Define Classes and Functions\n",
        "# -------------------------------\n",
        "\n",
        "# Callback for TensorBoard\n",
        "class TensorboardCallback(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super(TensorboardCallback, self).__init__(verbose)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        return True\n",
        "\n",
        "# Genetic Data Fetcher Class\n",
        "class GeneticDataFetcher:\n",
        "    def __init__(self, email):\n",
        "        self._email = email\n",
        "        Entrez.email = email\n",
        "\n",
        "    def fetch_sequence(self, accession):\n",
        "        try:\n",
        "            handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"fasta\")\n",
        "            record = SeqIO.read(handle, \"fasta\")\n",
        "            handle.close()\n",
        "            return str(record.seq)\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching sequence: {e}\")\n",
        "            return None\n",
        "\n",
        "# Sequence Analyzer Class\n",
        "class SequenceAnalyzer:\n",
        "    @staticmethod\n",
        "    def analyze_sequence(sequence, mutation_positions, expected_bases):\n",
        "        results = []\n",
        "        for pos in mutation_positions:\n",
        "            if pos < 0 or pos >= len(sequence):\n",
        "                results.append(f\"Position {pos} is out of range.\")\n",
        "                continue\n",
        "            actual_base = sequence[pos]\n",
        "            expected_base = expected_bases.get(pos, None)\n",
        "            if expected_base and actual_base != expected_base:\n",
        "                results.append(f\"Mutation at {pos}: expected {expected_base}, found {actual_base}\")\n",
        "            elif expected_base:\n",
        "                results.append(f\"No mutation at position {pos}.\")\n",
        "        return results\n",
        "\n",
        "# Treatment Predictor Class\n",
        "class TreatmentPredictor:\n",
        "    def __init__(self, input_shape):\n",
        "        self.model = self._build_model(input_shape)\n",
        "        self.tensorboard = self._setup_tensorboard()\n",
        "\n",
        "    def _build_model(self, input_shape):\n",
        "        model = keras.Sequential([\n",
        "            layers.Dense(128, activation='relu', input_shape=input_shape),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def _setup_tensorboard(self):\n",
        "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "        return tensorboard_callback\n",
        "\n",
        "    def train_model(self, X_train, y_train, X_val, y_val, epochs=50, batch_size=32):\n",
        "        self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                       validation_data=(X_val, y_val),\n",
        "                       callbacks=[self.tensorboard])\n",
        "\n",
        "    def evaluate_model(self, X_test, y_test):\n",
        "        y_pred_prob = self.model.predict(X_test)\n",
        "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "        return accuracy, precision, recall, f1\n",
        "\n",
        "    def predict_success_probability(self, new_patient_data):\n",
        "        return self.model.predict(new_patient_data)\n",
        "\n",
        "    def save_model(self, path):\n",
        "        self.model.save(path)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.model = keras.models.load_model(path)\n",
        "\n",
        "# Genetic Mutation Class\n",
        "class GeneticMutation:\n",
        "    def __init__(self, mutation_rate=0.01, elitism_rate=0.1, crossover_rate=0.7):\n",
        "        self.base_mutation_rate = mutation_rate\n",
        "        self.elitism_rate = elitism_rate\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.bases = ['A', 'T', 'C', 'G']\n",
        "\n",
        "    def mutate_sequence(self, sequence, variable_mutation_rate=None):\n",
        "        sequence = list(sequence)\n",
        "        for i in range(len(sequence)):\n",
        "            current_mutation_rate = self.base_mutation_rate\n",
        "            if variable_mutation_rate:\n",
        "                current_mutation_rate += variable_mutation_rate.get(i, 0)\n",
        "            if np.random.rand() < current_mutation_rate:\n",
        "                original_base = sequence[i]\n",
        "                new_bases = self.bases.copy()\n",
        "                new_bases.remove(original_base)\n",
        "                sequence[i] = random.choice(new_bases)\n",
        "        return ''.join(sequence)\n",
        "\n",
        "    def crossover(self, parent1, parent2):\n",
        "        if np.random.rand() > self.crossover_rate:\n",
        "            return parent1, parent2\n",
        "        point = random.randint(1, len(parent1) - 1)\n",
        "        child1 = parent1[:point] + parent2[point:]\n",
        "        child2 = parent2[:point] + parent1[point:]\n",
        "        return child1, child2\n",
        "\n",
        "    def select_elites(self, population, scores, elite_size):\n",
        "        sorted_indices = np.argsort(scores)[::-1]\n",
        "        elites = [population[i] for i in sorted_indices[:elite_size]]\n",
        "        return elites\n",
        "\n",
        "# Reinforcement Learning Environment\n",
        "class GeneMutationEnv(gym.Env):\n",
        "    def __init__(self, initial_sequence, expected_bases, mutation_positions, predictor, mutation_operator):\n",
        "        super(GeneMutationEnv, self).__init__()\n",
        "        self.initial_sequence = list(initial_sequence)\n",
        "        self.sequence = list(initial_sequence)\n",
        "        self.expected_bases = expected_bases  # Dict of position: expected_base\n",
        "        self.mutation_positions = mutation_positions  # List of positions to mutate\n",
        "        self.predictor = predictor\n",
        "        self.mutation_operator = mutation_operator\n",
        "        self.steps = 0\n",
        "\n",
        "        # Define action and observation space\n",
        "        self.action_space = spaces.MultiBinary(len(self.mutation_positions))\n",
        "        self.observation_space = spaces.Box(low=0, high=1,\n",
        "                                            shape=(len(self.mutation_positions),), dtype=np.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        self.sequence = list(self.initial_sequence)\n",
        "        self.steps = 0\n",
        "        return self._get_state()\n",
        "\n",
        "    def _get_state(self):\n",
        "        state = []\n",
        "        for pos in self.mutation_positions:\n",
        "            if pos < 0 or pos >= len(self.sequence):\n",
        "                state.append(0)\n",
        "            else:\n",
        "                state.append(1 if self.sequence[pos] == self.expected_bases.get(pos, self.sequence[pos]) else 0)\n",
        "        return np.array(state, dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        self.steps += 1\n",
        "        done = False\n",
        "        reward = 0\n",
        "\n",
        "        # Apply mutations based on action\n",
        "        for idx, mutate in enumerate(action):\n",
        "            if mutate:\n",
        "                pos = self.mutation_positions[idx]\n",
        "                if pos < 0 or pos >= len(self.sequence):\n",
        "                    continue\n",
        "                original_base = self.sequence[pos]\n",
        "                new_bases = self.mutation_operator.bases.copy()\n",
        "                new_bases.remove(original_base)\n",
        "                self.sequence[pos] = np.random.choice(new_bases)\n",
        "\n",
        "        # Evaluate the sequence\n",
        "        correct_mutations = 0\n",
        "        total_mutations = len(self.expected_bases)\n",
        "        for pos, expected_base in self.expected_bases.items():\n",
        "            if pos < 0 or pos >= len(self.sequence):\n",
        "                continue\n",
        "            if self.sequence[pos] == expected_base:\n",
        "                correct_mutations += 1\n",
        "\n",
        "        # Reward structure\n",
        "        if correct_mutations == total_mutations:\n",
        "            reward = 10\n",
        "            done = True\n",
        "        else:\n",
        "            reward = correct_mutations\n",
        "            if self.steps >= 20:\n",
        "                done = True\n",
        "\n",
        "        # Get next state\n",
        "        next_state = self._get_state()\n",
        "\n",
        "        return next_state, reward, done, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        print(f\"Current Sequence: {''.join(self.sequence)}\")\n",
        "\n",
        "# Data Processing Functions\n",
        "def get_k_mers(x, kmers):\n",
        "    '''Divide sequences into words'''\n",
        "    kmer = ''\n",
        "    for i in range(len(x)-kmers+1):\n",
        "        kmer = kmer + str(x[i:i+kmers]) + ' '\n",
        "    return kmer.strip()\n",
        "\n",
        "def generate_training_data(x, kmers):\n",
        "    '''Generate sentences from sequences'''\n",
        "    new_X = []\n",
        "    for i in range(len(x)):\n",
        "        new_X.append(get_k_mers(x[i], kmers))\n",
        "    new_X = np.array(new_X)\n",
        "    return new_X\n",
        "\n",
        "def vectorize_features(x, ngram_range=(4, 4)):\n",
        "    '''\n",
        "    Generate a dictionary of sentences having\n",
        "    made up of 4 words as default.\n",
        "    '''\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    tf = TfidfVectorizer(ngram_range=ngram_range, analyzer='word')\n",
        "    X_transf = tf.fit_transform(x)\n",
        "    return X_transf, tf\n",
        "\n",
        "# Pipeline Function\n",
        "def pipeline(df, model):\n",
        "    # get features and labels from the dataframe\n",
        "    sequences = df['sequence']\n",
        "    labels = df['class']\n",
        "\n",
        "    # create new features using kmers and vectorizer\n",
        "    new_X = generate_training_data(sequences, kmers=6)\n",
        "\n",
        "    X_transf, tf_vectorizer = vectorize_features(new_X, ngram_range=(4, 4))\n",
        "\n",
        "    # split the data in train and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_transf, labels,\n",
        "                                                        test_size=0.2,\n",
        "                                                        random_state=42,\n",
        "                                                        stratify=labels)\n",
        "\n",
        "    print('Number of training samples', X_train.shape[0])\n",
        "    print('Number of test samples', X_test.shape[0])\n",
        "    print('Number of features', X_train.shape[1])\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred_test))\n",
        "    print(confusion_matrix(y_test, y_pred_test))\n",
        "\n",
        "    return y_pred_test, model\n",
        "\n",
        "# Main Application Class\n",
        "class MainApplication:\n",
        "    def __init__(self, email, accession, mutation_positions, expected_bases, data_path):\n",
        "        self.fetcher = GeneticDataFetcher(email)\n",
        "        self.analyzer = SequenceAnalyzer()\n",
        "        self.mutation_operator = GeneticMutation()\n",
        "        self.accession = accession\n",
        "        self.mutation_positions = mutation_positions\n",
        "        self.expected_bases = expected_bases\n",
        "        self.data_path = data_path\n",
        "\n",
        "        # Fetch initial sequence\n",
        "        self.sequence = self.fetcher.fetch_sequence(accession)\n",
        "        if not self.sequence:\n",
        "            raise ValueError(\"Failed to fetch genetic sequence.\")\n",
        "\n",
        "        # Initialize Predictor\n",
        "        self.predictor = TreatmentPredictor(input_shape=(10,))  # Adjust input shape as needed\n",
        "\n",
        "    def load_data(self):\n",
        "        try:\n",
        "            data = pd.read_csv(self.data_path, sep='\\t')  # Assuming tab-separated\n",
        "            return data\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            return None\n",
        "\n",
        "    def run(self):\n",
        "        # Analyze initial sequence\n",
        "        analysis_results = self.analyzer.analyze_sequence(self.sequence, self.mutation_positions, self.expected_bases)\n",
        "        for result in analysis_results:\n",
        "            print(result)\n",
        "\n",
        "        # Load and prepare data\n",
        "        df_human = self.load_data()\n",
        "        if df_human is None:\n",
        "            print(\"Data loading failed. Exiting.\")\n",
        "            return\n",
        "\n",
        "        # Prepare data for ML\n",
        "        new_X = generate_training_data(df_human['sequence'], kmers=6)\n",
        "        X_transf, tf_vectorizer = vectorize_features(new_X, ngram_range=(4, 4))\n",
        "\n",
        "        # Split the data\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(X_transf, df_human['class'],\n",
        "                                                            test_size=0.3, random_state=42, stratify=df_human['class'])\n",
        "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp,\n",
        "                                                        test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "        # Train the model\n",
        "        self.predictor.train_model(X_train.toarray(), y_train, X_val.toarray(), y_val, epochs=50, batch_size=32)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy, precision, recall, f1 = self.predictor.evaluate_model(X_test.toarray(), y_test)\n",
        "        print(f\"Model Evaluation:\\nAccuracy: {accuracy:.2f}\\nPrecision: {precision:.2f}\\nRecall: {recall:.2f}\\nF1-Score: {f1:.2f}\")\n",
        "\n",
        "        # Initialize RL Environment\n",
        "        env = GeneMutationEnv(\n",
        "            initial_sequence=self.sequence,\n",
        "            expected_bases=self.expected_bases,\n",
        "            mutation_positions=self.mutation_positions,\n",
        "            predictor=self.predictor,\n",
        "            mutation_operator=self.mutation_operator\n",
        "        )\n",
        "        env = DummyVecEnv([lambda: env])\n",
        "\n",
        "        # Initialize RL Agent\n",
        "        tensorboard_log_dir = \"logs/rl/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        rl_model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=tensorboard_log_dir)\n",
        "        rl_model.learn(total_timesteps=10000, callback=TensorboardCallback())\n",
        "\n",
        "        # Choose the most well-mutated model\n",
        "        mutated_sequence = self.mutation_operator.mutate_sequence(self.sequence)\n",
        "        print(f\"Mutated Sequence: {mutated_sequence}\")\n",
        "        analysis_results = self.analyzer.analyze_sequence(mutated_sequence, self.mutation_positions, self.expected_bases)\n",
        "        for result in analysis_results:\n",
        "            print(result)\n",
        "\n",
        "        # Save models\n",
        "        model_path = \"models/treatment_predictor\"\n",
        "        rl_model_path = \"models/ppo_gene_mutation\"\n",
        "        os.makedirs(model_path, exist_ok=True)\n",
        "        os.makedirs(rl_model_path, exist_ok=True)\n",
        "        self.predictor.save_model(model_path)\n",
        "        rl_model.save(rl_model_path)\n",
        "        print(f\"Models saved at '{model_path}' and '{rl_model_path}'\")\n",
        "\n",
        "        # Visualize Results\n",
        "        self.visualize()\n",
        "\n",
        "        # Summarize Data\n",
        "        self.summarize_data()\n",
        "\n",
        "    def visualize(self):\n",
        "        plt.figure(figsize=(8,6))\n",
        "        plt.scatter(np.random.rand(100), np.random.rand(100), color='green', label='Mutations')\n",
        "        plt.scatter(0.5, 0.5, marker='^', color='red', label='Target')\n",
        "        plt.title('Gene Mutation Visualization')\n",
        "        plt.xlabel('Feature 1')\n",
        "        plt.ylabel('Feature 2')\n",
        "        plt.legend()\n",
        "        plt.savefig(\"mutation_visualization.png\")\n",
        "        plt.show()\n",
        "        print(\"Visualization saved as 'mutation_visualization.png'\")\n",
        "\n",
        "    def summarize_data(self):\n",
        "        print(\"Data Summary:\")\n",
        "        print(f\"Total Sequence Length: {len(self.sequence)}\")\n",
        "        print(f\"Mutation Positions: {self.mutation_positions}\")\n",
        "        print(f\"Expected Bases: {self.expected_bases}\")\n",
        "        print(\"TensorBoard logs available at 'logs/fit/' and 'logs/rl/'\")\n",
        "        print(\"To visualize TensorBoard, run the following commands in a new Colab cell:\")\n",
        "        print(\"```python\")\n",
        "        print(\"%load_ext tensorboard\")\n",
        "        print(\"%tensorboard --logdir logs/fit\")\n",
        "        print(\"%tensorboard --logdir logs/rl\")\n",
        "        print(\"```\")\n",
        "\n",
        "# -------------------------------\n",
        "# Step 5: Run the Application\n",
        "# -------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    email = \"your.email@example.com\"  # Replace with your email\n",
        "    accession = \"NC_000001\"  # Example accession number; replace with a valid one from your dataset\n",
        "    mutation_positions = [100, 200, 300]  # Example mutation positions\n",
        "    expected_bases = {100: 'A', 200: 'G', 300: 'T'}  # Expected bases at positions\n",
        "    data_path = '/content/drive/MyDrive/GeneLab/DNAsequential/human.txt'  # Update based on your Drive\n",
        "\n",
        "    app = MainApplication(email, accession, mutation_positions, expected_bases, data_path)\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvU1MV1IfzGl",
        "outputId": "3847ac14-d406-4dc1-f269-8eb35501effb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Listing files in the dataset directory:\n",
            "dog.txt  example_dna.fa  human.txt\n",
            "File /content/drive/MyDrive/GeneLab/DNAsequential/human.txt found.\n",
            "File /content/drive/MyDrive/GeneLab/DNAsequential/dog.txt found.\n",
            "File /content/drive/MyDrive/GeneLab/DNAsequential/chimpanzee.txt not found. Please check the path.\n",
            "File /content/drive/MyDrive/GeneLab/DNAsequential/example_dna.fa found.\n",
            "Mutation at 100: expected A, found N\n",
            "Mutation at 200: expected G, found N\n",
            "Mutation at 300: expected T, found N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/fit\n",
        "%tensorboard --logdir logs/rl\n"
      ],
      "metadata": {
        "id": "pbZxHLUMgtYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}